{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPrIEfjEAva6eIQ13G/dIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmainf/kaggle/blob/main/titanic_cope1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perished 死亡したかどうか 0 = No, 1 = Yes\n",
        "\n",
        "Pclass チケットのクラス 1 = 1st, 2 = 2nd, 3 = 3rd\n",
        "\n",
        "Name 名前\n",
        "\n",
        "Sex 性別\n",
        "\n",
        "Age 年齢\n",
        "\n",
        "SibSp 乗船していた兄弟姉妹・配偶者の数\n",
        "\n",
        "Parch 乗船していた親・子供の数\n",
        "\n",
        "Ticket チケット番号\n",
        "\n",
        "Fare チケット料金\n",
        "\n",
        "Cabin キャビン番号\n",
        "\n",
        "embarked 乗船した港 C = Cherbourg, Q = Queenstown, S = Southampton"
      ],
      "metadata": {
        "id": "R-6pPq3bap_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perished 死亡したかどうか 0 = No, 1 = Yes\n",
        "\n",
        "Pclass チケットのクラス 1 = 1st, 2 = 2nd, 3 = 3rd\n",
        "\n",
        "Sex 性別\n",
        "\n",
        "Age 年齢\n",
        "\n",
        "SibSp 乗船していた兄弟姉妹・配偶者の数\n",
        "\n",
        "Parch 乗船していた親・子供の数\n",
        "\n",
        "Fare チケット料金\n",
        "\n",
        "embarked 乗船した港 C = Cherbourg, Q = Queenstown, S = Southampton"
      ],
      "metadata": {
        "id": "aroFoMM0rTMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "n_epoc = 10\n",
        "batch_size = 32\n",
        "\n",
        "# 1. データ読み込み\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/GCI2025_colab/Competition01/data/'\n",
        "train_df = pd.read_csv(path + 'train.csv')\n",
        "test_df  = pd.read_csv(path + 'test.csv')\n",
        "\n",
        "# 2. 欠損値処理\n",
        "for df in (train_df, test_df):\n",
        "  df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
        "  df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
        "train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])\n",
        "test_df ['Embarked'] = test_df ['Embarked'].fillna(train_df['Embarked'].mode()[0])\n",
        "\n",
        "# 3. 不要列削除\n",
        "drop_cols = ['PassengerId','Name','Ticket','Cabin']\n",
        "train_df.drop(drop_cols, axis=1, inplace=True)\n",
        "test_df.drop(drop_cols, axis=1, inplace=True)\n",
        "\n",
        "# 4. ラベル分離\n",
        "X = train_df.drop('Perished', axis=1)\n",
        "y = train_df['Perished']\n",
        "X_test = test_df.copy()\n",
        "\n",
        "# 5. カテゴリ変数の one-hot\n",
        "X = pd.get_dummies(X, columns=['Sex','Embarked'])\n",
        "X_test = pd.get_dummies(X_test, columns=['Sex','Embarked'])\n",
        "# train にあって test にない列があれば 0 補完\n",
        "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "# 6. 標準化\n",
        "scaler = StandardScaler()\n",
        "X[X.columns]       = scaler.fit_transform(X[X.columns])\n",
        "X_test[X.columns]  = scaler.transform(X_test[X.columns])\n",
        "\n",
        "# 7. train/valid 分割\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    X.values, y.values, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 8. DataLoader 準備\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def to_dataset(x, y=None):\n",
        "    x = torch.from_numpy(x.astype(np.float32))\n",
        "    if y is None:\n",
        "        return torch.utils.data.TensorDataset(x)\n",
        "    y = torch.from_numpy(y).long()\n",
        "    return torch.utils.data.TensorDataset(x, y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    to_dataset(x_train, y_train), batch_size, shuffle=True\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    to_dataset(x_valid, y_valid), batch_size, shuffle=False\n",
        ")\n",
        "test_loader  = torch.utils.data.DataLoader(\n",
        "    to_dataset(X_test.values), batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# 9. モデル定義\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # 入力 → 128\n",
        "            nn.Linear(in_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            # 128 → 64\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            # 64 → 出力\n",
        "            nn.Linear(64, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "in_dim  = x_train.shape[1]\n",
        "out_dim = 2\n",
        "model   = MLP(in_dim, out_dim).to(device)\n",
        "\n",
        "# 10. 損失関数・オプティマイザ\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "# 11. 学習ループ\n",
        "for epoch in range(n_epoc):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss   = criterion(logits, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct   += (preds == yb).sum().item()\n",
        "        total     += xb.size(0)\n",
        "    train_loss, train_acc = total_loss/total, correct/total\n",
        "\n",
        "    model.eval()\n",
        "    v_loss, v_correct, v_total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in valid_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            loss   = criterion(logits, yb)\n",
        "            v_loss   += loss.item() * xb.size(0)\n",
        "            v_correct+= (logits.argmax(1)==yb).sum().item()\n",
        "            v_total  += xb.size(0)\n",
        "    val_loss, val_acc = v_loss/v_total, v_correct/v_total\n",
        "\n",
        "    print(f\"Epoch {epoch:03d} | \"\n",
        "          f\"train_loss: {train_loss:.4f}, accuracy: {train_acc:.4f} | \"\n",
        "          f\"valid_loss: {val_loss:.4f}, accuracy: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7N7KBtEAkcg",
        "outputId": "772d77e2-185a-4823-ad02-b8b1cdae08f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 000 | train_loss: 0.6302, accuracy: 0.6870 | valid_loss: 0.5550, accuracy: 0.7612\n",
            "Epoch 001 | train_loss: 0.5017, accuracy: 0.7929 | valid_loss: 0.4636, accuracy: 0.7910\n",
            "Epoch 002 | train_loss: 0.4671, accuracy: 0.8026 | valid_loss: 0.4463, accuracy: 0.7910\n",
            "Epoch 003 | train_loss: 0.4515, accuracy: 0.8010 | valid_loss: 0.4320, accuracy: 0.7985\n",
            "Epoch 004 | train_loss: 0.4515, accuracy: 0.8026 | valid_loss: 0.4302, accuracy: 0.7948\n",
            "Epoch 005 | train_loss: 0.4371, accuracy: 0.7994 | valid_loss: 0.4258, accuracy: 0.8060\n",
            "Epoch 006 | train_loss: 0.4289, accuracy: 0.8074 | valid_loss: 0.4245, accuracy: 0.8022\n",
            "Epoch 007 | train_loss: 0.4245, accuracy: 0.8042 | valid_loss: 0.4223, accuracy: 0.8060\n",
            "Epoch 008 | train_loss: 0.4238, accuracy: 0.8042 | valid_loss: 0.4232, accuracy: 0.8060\n",
            "Epoch 009 | train_loss: 0.4129, accuracy: 0.8266 | valid_loss: 0.4226, accuracy: 0.8172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/GCI2025_colab/Competition01/\"\n",
        "# 3. サブミッション用テンプレート読み込み\n",
        "submission = pd.read_csv(path + 'gender_submission.csv')\n",
        "\n",
        "# 4. Perished 列を置き換え\n",
        "submission['Perished'] = all_preds\n",
        "submission.to_csv(path + 'submission.csv', index=False)\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "NMwgDDRpEpvx"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}